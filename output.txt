       modelEnv("Pendulum-v1", ModelParameter(training_episodes=50, trajectory=10, store_frequency=5))
/Users/svenduve/.julia/conda/3/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     0.119348  -0.180086  -0.502249  -0.790596  -0.966643  -0.990446  -0.86575  -0.628253  -0.343968  -0.0441126
└     ⋮                                                      ⋮                                         
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.180086  -0.502249  -0.790596  -0.966643  -0.990446  -0.86575  -0.628253  -0.343968  -0.0441126  0.228843
└      ⋮                                                      ⋮                                          
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.0560557  0.0391254  0.34557  0.347843  0.710486  0.534727  0.377553  0.786384  -0.0476146  0.310932
└      ⋮                                                  ⋮                                         
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.124031  -0.541375  -1.13617  -1.31449  -1.70093  -1.40048  -1.00581  -1.13035  0.00350202  -0.0820889
└      ⋮                                                   ⋮                                        
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -4.70642  -6.68705  -9.16295  -12.1102  -14.7119  -15.336  -12.8048  -10.4623  -8.00506  -6.37878
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -0.747914  -0.674906  -0.691877  -0.684027  -0.640899  -0.7011  -0.74405  -0.675108  -0.806229  -0.724029
Episode: 0 | Accuracy: 0.02 | Model Loss: 5.238684 | Reward Loss: 31.75676|  Steps: 200
Episode: 1 | Accuracy: 0.03 | Model Loss: 4.1706448 | Reward Loss: 46.11404|  Steps: 200
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
Episode: 2 | Accuracy: 0.29 | Model Loss: 0.043008674 | Reward Loss: 0.43998757|  Steps: 200
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
Episode: 3 | Accuracy: 0.36 | Model Loss: 0.027503945 | Reward Loss: 0.16139638|  Steps: 200
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
Episode: 4 | Accuracy: 0.48 | Model Loss: 0.009105717 | Reward Loss: 0.32020697|  Steps: 200
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Warning: First function call produced NaNs. Exiting. Double check that none of the initial conditions, parameters, or timespan values are NaN.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/initdt.jl:249
┌ Warning: Automatic dt set the starting dt as NaN, causing instability. Exiting.
└ @ OrdinaryDiffEq ~/.julia/packages/OrdinaryDiffEq/gjQVg/src/solve.jl:554
┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.
└ @ SciMLBase ~/.julia/packages/SciMLBase/VdcHg/src/integrator_interface.jl:569
sol.retcode = SciMLBase.ReturnCode.DtNaN
Solve most probably divergent, this only affects the current hidden state solve, but has no effect on prior or further solves
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.726122  -0.811933  -0.897869  -0.960944  -0.994725  -0.996026  -0.963415  -0.902752  -0.822803  -0.743428
│     -0.687566  -0.583751  -0.440262  -0.276743  -0.102576   0.089058   0.268015   0.430161   0.568327   0.668816
└     -2.16302   -2.69581   -3.34901   -3.50975   -3.55293   -3.83865   -3.64312   -3.46678   -3.19599   -2.5629
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.811933  -0.897869  -0.960944  -0.994725  -0.996026  -0.963415  -0.902752  -0.822803  -0.743428  -0.663673
│     -0.583751  -0.440262  -0.276743  -0.102576   0.089058   0.268015   0.430161   0.568327   0.668816   0.748023
└     -2.69581   -3.34901   -3.50975   -3.55293   -3.83865   -3.64312   -3.46678   -3.19599   -2.5629    -2.24924
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.839601  -0.925289  -0.94385   -1.06461    -1.03644   -0.993631  -0.919284  -0.818491  -0.722259  -0.641393
│     -0.780411  -0.594974  -0.245594  -0.0993789   0.118864   0.257943   0.411774   0.513957   0.640234   0.666132
└     -3.46245   -3.52779   -3.47173   -3.61561    -3.86453   -3.70223   -3.50819   -3.23255   -2.62731   -2.29647
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     0.027668  0.0274199  -0.0170936   0.0698802    0.0404091  0.0302163  0.0165319  -0.00431246  -0.0211686  -0.0222801
│     0.19666   0.154712   -0.0311495  -0.00319675  -0.0298061  0.0100717  0.0183867   0.0543693    0.0285825   0.0818903
└     0.766639  0.17878    -0.0380206   0.0626791    0.0258813  0.0591092  0.04141     0.0365639    0.0644066   0.04723
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -6.14876  -7.07039  -8.33586  -9.41944  -10.4988  -10.7915  -9.56565  -8.47536  -7.46032  -6.46159
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -5.99963  -7.04521  -8.56187  -9.64721  -10.4856  -10.6777  -9.53795  -8.48224  -7.39518  -6.60966
Episode: 5 | Accuracy: 0.58 | Model Loss: 0.006753852 | Reward Loss: 0.105007246|  Steps: 200
Episode: 6 | Accuracy: 0.58 | Model Loss: 0.0072425944 | Reward Loss: 0.07316494|  Steps: 200
Episode: 7 | Accuracy: 0.69 | Model Loss: 0.0050374335 | Reward Loss: 0.061529983|  Steps: 200
Episode: 8 | Accuracy: 0.8 | Model Loss: 0.003179601 | Reward Loss: 0.065796405|  Steps: 200
Episode: 9 | Accuracy: 0.79 | Model Loss: 0.0029691958 | Reward Loss: 0.035205744|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│      0.950815   0.964969   0.974692   0.98373    0.988563   0.993591   0.995612    0.996409    0.997638    0.998803
│     -0.309758  -0.262366  -0.223551  -0.179655  -0.150807  -0.113032  -0.0935746  -0.0846661  -0.0686895  -0.0489175
└      1.36072    0.989311   0.800327   0.896414   0.585021   0.762219   0.391242    0.178882    0.320479    0.396131
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│      0.964969   0.974692   0.98373    0.988563   0.993591   0.995612    0.996409    0.997638    0.998803    0.998955
│     -0.262366  -0.223551  -0.179655  -0.150807  -0.113032  -0.0935746  -0.0846661  -0.0686895  -0.0489175  -0.0456986
└      0.989311   0.800327   0.896414   0.585021   0.762219   0.391242    0.178882    0.320479    0.396131    0.0644512
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│      0.962559   1.01162    0.966544   0.963547   0.992018   1.0024     1.01766     1.01944    1.0195     1.01861
│     -0.435362  -0.229157  -0.230792  -0.20318   -0.11621   -0.111537  -0.0875149  -0.104552  -0.080423  -0.0608146
└      1.16403    0.735327   0.781483   0.558413   0.727172   0.405906   0.0840079   0.286447   0.355846   0.00754446
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│      0.00240993  -0.0369274   0.0171853  0.0250163  0.00157291  -0.00678337  -0.0212542   -0.0217977  -0.0206959  -0.0196573
│      0.172996     0.00560553  0.0511367  0.0523724  0.00317818   0.0179628    0.00284875   0.0358626   0.0315054   0.015116
└     -0.174718     0.0650003   0.114931   0.0266083  0.0350475   -0.0146642    0.0948741    0.0340323   0.0402848   0.0569067
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -0.285201  -0.168352  -0.117975  -0.114372  -0.0608879  -0.0745693  -0.0249873  -0.012255  -0.0157151  -0.0219544
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -0.21376  -0.167241  -0.244554  -0.293641  -0.224858  -0.283153  -0.212311  -0.184845  -0.173438  -0.243406
Episode: 10 | Accuracy: 0.66 | Model Loss: 0.2643175 | Reward Loss: 0.16178711|  Steps: 200

Episode: 11 | Accuracy: 0.77 | Model Loss: 0.0024250252 | Reward Loss: 0.02474818|  Steps: 200
Episode: 12 | Accuracy: 0.69 | Model Loss: 0.0034162463 | Reward Loss: 0.03641551|  Steps: 200
Episode: 13 | Accuracy: 0.79 | Model Loss: 0.00265983 | Reward Loss: 0.040965565|  Steps: 200
Episode: 14 | Accuracy: 0.83 | Model Loss: 0.0016817307 | Reward Loss: 0.024676342|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.437527  -0.33466   -0.268305  -0.222851  -0.213371  -0.228007  -0.279486  -0.359145  -0.478431  -0.606732
│     -0.899205  -0.942339  -0.963334  -0.974853  -0.976971  -0.973659  -0.96015   -0.933282  -0.878125  -0.794906
└      2.74979    2.23206    1.39222    0.937896   0.194287  -0.300136  -1.06457   -1.68186   -2.63031   -3.06152
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.33466   -0.268305  -0.222851  -0.213371  -0.228007  -0.279486  -0.359145  -0.478431  -0.606732  -0.739897
│     -0.942339  -0.963334  -0.974853  -0.976971  -0.973659  -0.96015   -0.933282  -0.878125  -0.794906  -0.67272
└      2.23206    1.39222    0.937896   0.194287  -0.300136  -1.06457   -1.68186   -2.63031   -3.06152   -3.61947
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.286066  -0.266706  -0.21759   -0.197416  -0.211967  -0.2674    -0.351043  -0.475834  -0.612463  -0.754937
│     -0.983181  -0.970155  -0.957221  -0.955409  -0.958448  -0.959434  -0.938575  -0.897959  -0.812597  -0.692191
└      2.25935    1.36245    0.939044   0.223323  -0.272759  -1.0463    -1.6573    -2.62818   -3.03705   -3.60155
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.048594   -0.00159878  -0.00526138  -0.0159547  -0.0160399  -0.0120864    -0.00810191  -0.00259724   0.00573057   0.0150397
│      0.0408419   0.00682122  -0.0176315   -0.0215625  -0.0152117  -0.000715554   0.00529283   0.0198343    0.017691     0.0194708
└     -0.0272889   0.0297722   -0.00114834  -0.029036   -0.0273768  -0.0182644    -0.0245557   -0.00213385  -0.0244784   -0.0179236
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -4.85236  -4.15489  -3.59157  -3.31192  -3.19545  -3.25204  -3.55132  -4.04203  -4.97766  -5.87793
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -4.78967  -4.20064  -3.6589  -3.41599  -3.26397  -3.32244  -3.57411  -4.05301  -4.98445  -5.91435
Episode: 15 | Accuracy: 0.93 | Model Loss: 0.00086328835 | Reward Loss: 0.0048931567|  Steps: 200
Episode: 16 | Accuracy: 0.84 | Model Loss: 0.02545998 | Reward Loss: 0.05153371|  Steps: 200
Episode: 17 | Accuracy: 0.88 | Model Loss: 0.0019268065 | Reward Loss: 0.039649427|  Steps: 200
Episode: 18 | Accuracy: 0.88 | Model Loss: 0.0017137384 | Reward Loss: 0.01752855|  Steps: 200
Episode: 19 | Accuracy: 0.83 | Model Loss: 0.0014084983 | Reward Loss: 0.023224004|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.519673  -0.531121  -0.579907  -0.647664  -0.726122  -0.811933  -0.897869  -0.960944  -0.994725  -0.996026
│     -0.854365  -0.847296  -0.814683  -0.761926  -0.687566  -0.583751  -0.440262  -0.276743  -0.102576   0.089058
└      0.419558  -0.269101  -1.17381   -1.718     -2.16302   -2.69581   -3.34901   -3.50975   -3.55293   -3.83865
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.531121  -0.579907  -0.647664  -0.726122  -0.811933  -0.897869  -0.960944  -0.994725  -0.996026  -0.963415
│     -0.847296  -0.814683  -0.761926  -0.687566  -0.583751  -0.440262  -0.276743  -0.102576   0.089058   0.268015
└     -0.269101  -1.17381   -1.718     -2.16302   -2.69581   -3.34901   -3.50975   -3.55293   -3.83865   -3.64312
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.498386  -0.60936   -0.682581  -0.739092  -0.83087   -0.919523  -0.981245  -1.01955    -1.00486  -0.967314
│     -0.907875  -0.733931  -0.739325  -0.645755  -0.554228  -0.40536   -0.240858  -0.0673735   0.13953   0.316647
└     -0.292926  -1.25407   -1.76939   -2.18667   -2.72851   -3.38867   -3.5963    -3.63859    -3.9234   -3.79358
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.0327355   0.029453    0.0349174   0.0129696   0.0189375   0.0216535   0.0203012   0.024829    0.00883228   0.0038994
│      0.060579   -0.0807517  -0.0226014  -0.0418105  -0.0295227  -0.0349022  -0.0358851  -0.0352021  -0.050472    -0.0486325
└      0.0238248   0.0802613   0.0513921   0.023649    0.0327008   0.0396688   0.0865548   0.0856516   0.0847509    0.150464
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -4.50052  -4.55043  -4.9315  -5.4729  -6.14876  -7.07039  -8.33586  -9.41944  -10.4988  -10.7915
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -4.46915  -4.77099  -5.05891  -5.62807  -6.2649  -7.15787  -8.32006  -9.34847  -10.4283  -10.6446
Episode: 20 | Accuracy: 0.77 | Model Loss: 0.0026090574 | Reward Loss: 0.016225737|  Steps: 200

Episode: 21 | Accuracy: 0.82 | Model Loss: 0.0021102852 | Reward Loss: 0.010781644|  Steps: 200
Episode: 22 | Accuracy: 0.73 | Model Loss: 0.0057074884 | Reward Loss: 0.032701194|  Steps: 200
Episode: 23 | Accuracy: 0.83 | Model Loss: 0.0015553028 | Reward Loss: 0.028827727|  Steps: 200
Episode: 24 | Accuracy: 0.88 | Model Loss: 0.001225156 | Reward Loss: 0.01300106|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     0.908815  0.856695  0.78174   0.68199   0.534545  0.333454  0.0948568  -0.180781  -0.47857  -0.755005
│     0.4172    0.515823  0.623604  0.731361  0.84514   0.942766  0.995491    0.983523   0.87805   0.655719
└     2.06571   2.23211   2.62755   2.93942   3.73023   4.48008   4.89931     5.5356     6.34489   7.13274
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     0.856695  0.78174   0.68199   0.534545  0.333454  0.0948568  -0.180781  -0.47857  -0.755005  -0.943609
│     0.515823  0.623604  0.731361  0.84514   0.942766  0.995491    0.983523   0.87805   0.655719   0.331062
└     2.23211   2.62755   2.93942   3.73023   4.48008   4.89931     5.5356     6.34489   7.13274    7.55412
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     0.888945  0.754878  0.673151  0.530627  0.312729  0.0845613  -0.186419  -0.472385  -0.734028  -0.929939
│     0.437026  0.647876  0.699619  0.820015  0.87762   0.936199    0.926026   0.826442   0.623595   0.330911
└     2.19238   2.61586   2.95004   3.73945   4.47022   4.93402     5.56137    6.36433    7.12727    7.56382
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.032249    0.0268626   0.00883973   0.0039174   0.0207255   0.0102955   0.00563832  -0.00618511  -0.0209769   -0.0136703
│      0.0787961  -0.0242717   0.0317425    0.0251254   0.0651464   0.0592924   0.057497     0.0516073    0.0321241    0.000150591
└      0.0397272   0.0116887  -0.0106204   -0.00921893  0.0098629  -0.0347142  -0.0257635   -0.0194373    0.00547457  -0.00970173
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -0.612883  -0.791962  -1.14487  -1.53954  -2.40576  -3.52574  -4.57884  -6.13605  -8.31067  -10.9755
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -0.587626  -0.784854  -1.12634  -1.5225  -2.52267  -3.66266  -4.72403  -6.31562  -8.5211  -11.1627
Episode: 25 | Accuracy: 0.86 | Model Loss: 0.0018394531 | Reward Loss: 0.008657118|  Steps: 200
Episode: 26 | Accuracy: 0.8 | Model Loss: 0.04128174 | Reward Loss: 0.2304043|  Steps: 200
Episode: 27 | Accuracy: 0.93 | Model Loss: 0.0010346747 | Reward Loss: 0.018615505|  Steps: 200
Episode: 28 | Accuracy: 0.85 | Model Loss: 0.0017406552 | Reward Loss: 0.010225487|  Steps: 200
Episode: 29 | Accuracy: 0.88 | Model Loss: 0.0017429434 | Reward Loss: 0.01856398|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.503322  -0.571084  -0.649544  -0.744006  -0.836748  -0.91421   -0.970229  -0.998127   -0.993244  -0.961101
│     -0.864099  -0.820892  -0.760324  -0.668173  -0.547588  -0.405241  -0.24219   -0.0611709   0.116043   0.276196
└     -0.897787  -1.60773   -1.98319   -2.64122   -3.04543   -3.24474   -3.45238   -3.66827    -3.55028   -3.27058
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.571084  -0.649544  -0.744006  -0.836748  -0.91421   -0.970229  -0.998127   -0.993244  -0.961101  -0.913203
│     -0.820892  -0.760324  -0.668173  -0.547588  -0.405241  -0.24219   -0.0611709   0.116043   0.276196   0.407506
└     -1.60773   -1.98319   -2.64122   -3.04543   -3.24474   -3.45238   -3.66827    -3.55028   -3.27058   -2.79774
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.560623  -0.651284  -0.749155  -0.840563  -0.916409  -0.97299  -1.00148    -0.995435  -0.96329   -0.914651
│     -0.851181  -0.718363  -0.648217  -0.540036  -0.389569  -0.24026  -0.0556216   0.123765   0.283374   0.410173
└     -1.62281   -1.88228   -2.67759   -3.01185   -3.21284   -3.42566  -3.66282    -3.53991   -3.26442   -2.78926
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.0104613   0.00173974   0.00514925   0.00381452   0.00219923   0.0027613    0.00335687   0.00219125   0.00218832   0.00144857
│      0.0302896  -0.0419609   -0.0199559   -0.00755167  -0.0156712   -0.00193085  -0.00554933  -0.00772242  -0.00717756  -0.00266787
└      0.0150844  -0.100907     0.0363779   -0.0335832   -0.0319021   -0.0267258   -0.00545382  -0.0103698   -0.00616169  -0.00848007
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -4.48336  -5.00744  -5.58194  -6.50536  -7.49388  -8.47533  -9.58438  -10.8356  -10.4145  -9.26247
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -4.40756  -5.11723  -5.64654  -6.54463  -7.51578  -8.49287  -9.61287  -10.8647  -10.384  -9.28653
Episode: 30 | Accuracy: 0.86 | Model Loss: 0.0032082547 | Reward Loss: 0.024379857|  Steps: 200

Episode: 31 | Accuracy: 0.94 | Model Loss: 0.00055833807 | Reward Loss: 0.02846044|  Steps: 200
Episode: 32 | Accuracy: 0.94 | Model Loss: 0.0006677486 | Reward Loss: 0.006235837|  Steps: 200
Episode: 33 | Accuracy: 0.97 | Model Loss: 0.0004118282 | Reward Loss: 0.0054580467|  Steps: 200
Episode: 34 | Accuracy: 0.82 | Model Loss: 0.00225108 | Reward Loss: 0.050595455|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.334236  -0.516672  -0.69914   -0.852482  -0.962685  -0.999929   -0.95583   -0.834999  -0.653945  -0.439099
│      0.94249    0.856183   0.714985   0.522757   0.270623  -0.0119123  -0.293921  -0.550252  -0.756542  -0.898439
└      3.13501    4.04331    4.62469    4.93042    5.52081    5.71906     5.72829    5.68678    5.50686    5.16384
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.516672  -0.69914   -0.852482  -0.962685  -0.999929   -0.95583   -0.834999  -0.653945  -0.439099  -0.21801
│      0.856183   0.714985   0.522757   0.270623  -0.0119123  -0.293921  -0.550252  -0.756542  -0.898439  -0.975947
└      4.04331    4.62469    4.93042    5.52081    5.71906     5.72829    5.68678    5.50686    5.16384    4.69642
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.515701  -0.701849  -0.869864  -0.960121  -1.01171    -0.958199  -0.831897  -0.649916  -0.435585  -0.217039
│      0.878379   0.737286   0.527509   0.282663  -0.0165812  -0.292322  -0.554239  -0.75667   -0.889486  -0.956148
└      4.04152    4.61846    4.96404    5.49157    5.71899     5.7286     5.67304    5.50703    5.1601     4.68454
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│     -0.00097084   0.00270844   0.0173823   -0.00256401  0.0117821    0.00236934   -0.00310189  -0.00402963   -0.00351444  -0.000970557
│     -0.0221958   -0.0223017   -0.00475281  -0.0120396   0.00466895  -0.00159967    0.00398701   0.000127614  -0.00895292  -0.0197984
└      0.00178194   0.00622797  -0.0336175    0.0292473   7.15256f-5  -0.000311852   0.0137329   -0.000170231   0.0037322    0.0118766
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -4.63881  -6.10296  -7.64012  -9.14858  -11.2708  -13.0657  -11.3669  -9.78446  -8.24955  -6.77063
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -4.65158  -6.07842  -7.63795  -9.14089  -11.2992  -12.9658  -11.3879  -9.82132  -8.2592  -6.75746
Episode: 35 | Accuracy: 0.94 | Model Loss: 0.0009262571 | Reward Loss: 0.004406906|  Steps: 200
Episode: 36 | Accuracy: 0.8 | Model Loss: 0.0030153564 | Reward Loss: 0.010378527|  Steps: 200
Episode: 37 | Accuracy: 0.95 | Model Loss: 0.0005744955 | Reward Loss: 0.006961832|  Steps: 200
Episode: 38 | Accuracy: 0.77 | Model Loss: 0.0023208095 | Reward Loss: 0.025082368|  Steps: 200
Episode: 39 | Accuracy: 0.86 | Model Loss: 0.0014968178 | Reward Loss: 0.022912325|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.661739  -0.365514  -0.0729489   0.197892   0.413649   0.59208    0.728108   0.829375   0.897946   0.944391
│     -0.749734  -0.930806  -0.997336   -0.980224  -0.910437  -0.805879  -0.685463  -0.558692  -0.440105  -0.328824
└      7.36922    6.97902    6.02343     5.44441    4.54503    4.14358    3.6384     3.24863    2.74183    2.41315
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.365514  -0.0729489   0.197892   0.413649   0.59208    0.728108   0.829375   0.897946   0.944391   0.971586
│     -0.930806  -0.997336   -0.980224  -0.910437  -0.805879  -0.685463  -0.558692  -0.440105  -0.328824  -0.236688
└      6.97902    6.02343     5.44441    4.54503    4.14358    3.6384     3.24863    2.74183    2.41315    1.92204
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.458117  -0.0867154   0.18481   0.399991   0.579202   0.711964   0.819682   0.891105   0.942077   0.974572
│     -0.872245  -0.958516   -0.97375  -0.920012  -0.80812   -0.683871  -0.547945  -0.417924  -0.306453  -0.208852
└      6.83829    6.11151     5.39838   4.59413    4.13105    3.66693    3.27384    2.7699     2.42648    1.94764
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│      0.092603    0.0137665   0.0130815    0.0136574   0.0128781    0.0161433    0.00969356   0.00684106   0.00231457  -0.00298631
│     -0.0585603  -0.0388193  -0.00647438   0.00957555  0.00224096  -0.00159127  -0.0107466   -0.0221817   -0.0223708   -0.0278361
└      0.140723   -0.0880852   0.0460315   -0.0490994   0.0125303   -0.0285256   -0.0252142   -0.0280688   -0.0133212   -0.0256004
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -10.694  -8.65657  -6.33155  -4.84662  -3.37876  -2.59563  -1.89487  -1.40712  -0.959442  -0.697252
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -10.7337  -8.951  -6.38334  -4.88529  -3.36899  -2.62507  -1.9262  -1.42554  -0.956531  -0.672686
Episode: 40 | Accuracy: 0.96 | Model Loss: 0.0006076246 | Reward Loss: 0.0038881004|  Steps: 200

Episode: 41 | Accuracy: 0.88 | Model Loss: 0.000866808 | Reward Loss: 0.007810363|  Steps: 200
Episode: 42 | Accuracy: 0.96 | Model Loss: 0.0006232464 | Reward Loss: 0.0054654363|  Steps: 200
Episode: 43 | Accuracy: 0.98 | Model Loss: 0.0005904966 | Reward Loss: 0.02906394|  Steps: 200
Episode: 44 | Accuracy: 0.98 | Model Loss: 0.00046303976 | Reward Loss: 0.014712301|  Steps: 200
┌ Info: Current State: 
│   S =
│    3×10 Matrix{Float32}:
│     -0.422744  -0.255358  -0.128678  -0.0324522   0.0195597   0.0312486  0.00329196  -0.0699383  -0.16724   -0.286778
│      0.906249   0.966847   0.991686   0.999473    0.999809    0.999512   0.999995     0.997551    0.985916   0.957997
└     -4.44679   -3.56508   -2.58364   -1.93155    -1.04038    -0.233855   0.559234     1.46575     1.96068    2.45666
┌ Info: Next State: 
│   S´ =
│    3×10 Matrix{Float32}:
│     -0.255358  -0.128678  -0.0324522   0.0195597   0.0312486  0.00329196  -0.0699383  -0.16724   -0.286778  -0.43144
│      0.966847   0.991686   0.999473    0.999809    0.999512   0.999995     0.997551    0.985916   0.957997   0.902142
└     -3.56508   -2.58364   -1.93155    -1.04038    -0.233855   0.559234     1.46575     1.96068    2.45666    3.10453
┌ Info: Predicted Next State
│   Ŝ =
│    3×10 Matrix{Float32}:
│     -0.255434  -0.152312  -0.0489845   0.00155962   0.0179956  -0.0026083  -0.0733022  -0.163655  -0.286417  -0.435048
│      0.959796   0.997306   0.99473     0.997327     0.990735    0.996676    0.998213    0.996639   0.969121   0.913381
└     -3.45167   -2.48692   -1.94497    -1.05614     -0.263127    0.503483    1.4067      1.86336    2.35867    3.01296
┌ Info: Difference
│   S´ .- Ŝ =
│    3×10 Matrix{Float32}:
│      7.59661f-5   0.0236345   0.0165324   0.018      0.0132529   0.00590026   0.00336394   -0.0035843  -0.000361562   0.00360781
│      0.00705111  -0.00561905  0.00474316  0.0024817  0.00877649  0.00331885  -0.000661254  -0.0107232  -0.0111237    -0.0112391
└     -0.113412    -0.0967209   0.0134211   0.0157648  0.0292721   0.0557504    0.0590451     0.0973208   0.0979939     0.0915647
┌ Info: Reward: 
│   R' =
│    1×10 adjoint(::Vector{Any}) with eltype Any:
└     -6.00833  -4.61919  -3.55732  -2.9444  -2.51471  -2.37574  -2.48943  -2.90989  -3.41057  -4.06951
┌ Info: Predicted Reward: 
│   Rϕ(vcat(S, A, Ŝ)) =
│    1×10 Matrix{Float32}:
└     -5.94426  -4.5627  -3.60863  -2.99553  -2.54671  -2.38675  -2.5037  -2.94202  -3.45268  -4.11476
Episode: 45 | Accuracy: 0.81 | Model Loss: 0.00237898 | Reward Loss: 0.003699267|  Steps: 200

Episode: 46 | Accuracy: 0.96 | Model Loss: 0.0005052127 | Reward Loss: 0.003670133|  Steps: 200
Episode: 47 | Accuracy: 0.97 | Model Loss: 0.0003544039 | Reward Loss: 0.0042550312|  Steps: 200
Episode: 48 | Accuracy: 0.82 | Model Loss: 0.0017461992 | Reward Loss: 0.01937276|  Steps: 200
Episode: 49 | Accuracy: 0.81 | Model Loss: 0.0018755574 | Reward Loss: 0.0033103048|  Steps: 200

